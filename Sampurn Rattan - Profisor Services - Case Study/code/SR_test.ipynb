{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all libraries and variables\n",
    "import os,sys  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import fasttext\n",
    "\n",
    "data_path = './data/amazon_review_polarity_csv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_train_dataset(dataframe, shuffle = False, encode_ascii = False, clean_strings = False, label_prefix = '__label__'):\n",
    "    # Transform train file\n",
    "    df = dataframe[['name','description']].apply(lambda x: x.str.replace(',',' '))\n",
    "    df['class'] = label_prefix + dataframe['class'].astype(str) + ' '\n",
    "    if clean_strings:\n",
    "        df[['name','description']] = df[['name','description']].apply(lambda x: x.str.replace('\"',''))\n",
    "        df[['name','description']] = df[['name','description']].apply(lambda x: x.str.replace('\\'',' \\' '))\n",
    "        df[['name','description']] = df[['name','description']].apply(lambda x: x.str.replace('.',' . '))\n",
    "        df[['name','description']] = df[['name','description']].apply(lambda x: x.str.replace('(',' ( '))\n",
    "        df[['name','description']] = df[['name','description']].apply(lambda x: x.str.replace(')',' ) '))\n",
    "        df[['name','description']] = df[['name','description']].apply(lambda x: x.str.replace('!',' ! '))\n",
    "        df[['name','description']] = df[['name','description']].apply(lambda x: x.str.replace('?',' ? '))\n",
    "        df[['name','description']] = df[['name','description']].apply(lambda x: x.str.replace(':',' '))\n",
    "        df[['name','description']] = df[['name','description']].apply(lambda x: x.str.replace(';',' '))\n",
    "        df[['name','description']] = df[['name','description']].apply(lambda x: x.str.lower())\n",
    "    if shuffle:\n",
    "        df.sample(frac=1).reset_index(drop=True)\n",
    "    if encode_ascii :\n",
    "        df[['name','description']] = df[['name','description']].apply(lambda x: x.str.normalize('NFKD').str.encode('ascii','ignore').str.decode('utf-8'))\n",
    "    df['name'] = ' ' + df['name'] + ' '\n",
    "    df['description'] = ' ' + df['description'] + ' '\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 4.47 s, total: 1min 20s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Load train set\n",
    "train_file = data_path + 'train.csv'\n",
    "df_sentiment_train = pd.read_csv(train_file, header = None, names = ['class','name','description'])\n",
    "\n",
    "#Load test set\n",
    "test_file = data_path + 'test.csv'\n",
    "df_sentiment_test = pd.read_csv(test_file, header = None, names = ['class','name','description'])\n",
    "\n",
    "# Transform datasets\n",
    "df_train_clean = clean_train_dataset(df_sentiment_train, True, False)\n",
    "df_test_clean = clean_train_dataset(df_sentiment_test, False, False)\n",
    "\n",
    "# Write cleaned files to disk\n",
    "train_file_clean = data_path + 'amazon.train'\n",
    "df_train_clean.to_csv(train_file_clean, header = None, index = False, columns = ['class','name','description'] )\n",
    "\n",
    "test_file_clean = data_path + 'amazon.test'\n",
    "df_test_clean.to_csv(test_file_clean, header = None, index = False, columns = ['class','name','description'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 47s, sys: 11.9 s, total: 14min 59s\n",
      "Wall time: 5min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parameters\n",
    "dim = 10\n",
    "lr = 0.1\n",
    "epoch = 5\n",
    "min_count = 1\n",
    "word_ngrams = 2\n",
    "bucket = 10000000\n",
    "thread = 12\n",
    "label_prefix = '__label__'\n",
    "\n",
    "# Train a classifier\n",
    "output_file = data_path + 'amazon_model'\n",
    "classifier = fasttext.supervised(train_file_clean, output_file, dim = dim, lr = lr, epoch = epoch, min_count = min_count, word_ngrams = word_ngrams, bucket = bucket, thread = thread, label_prefix = label_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Precision:', 0.941815)\n",
      "('Recall:', 0.941815)\n",
      "('Number of examples:', 400000)\n",
      "CPU times: user 9.74 s, sys: 84 ms, total: 9.82 s\n",
      "Wall time: 9.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Evaluate classifier\n",
    "result = classifier.test(test_file_clean)\n",
    "print('Precision:', result.precision)\n",
    "print('Recall:', result.recall)\n",
    "print ('Number of examples:', result.nexamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 s, sys: 60 ms, total: 17.4 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load real-world validation dataset \n",
    "validation_dataset = pd.read_csv(data_path + 'sentences.csv', encoding=\"UTF-8\")\n",
    "# Preprocessing validation dataset\n",
    "# Remove b' unicode from comment_message column\n",
    "validation_dataset['comment_message'] = validation_dataset['comment_message'].apply(lambda x: x[1:])\n",
    "# Remove emoji characters\n",
    "validation_dataset[['comment_message']] = validation_dataset[['comment_message']].apply(lambda x: x.str.replace(r'\\\\x[0-9A-Fa-f]*',''))\n",
    "\n",
    "\n",
    "class_dict={\n",
    "    1:\"Negative\",\n",
    "    2:\"Positive\"\n",
    "}\n",
    "\n",
    "validation_dataset['label'] = validation_dataset['comment_message'].apply(lambda x: classifier.predict_proba(x)[0][0][0])\n",
    "validation_dataset['label'] = validation_dataset['label'].apply(lambda x: class_dict[int(x)])\n",
    "validation_dataset['certainty'] = validation_dataset['comment_message'].apply(lambda x: classifier.predict_proba(x)[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_message</th>\n",
       "      <th>label</th>\n",
       "      <th>certainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1538183672909402_1541895645871538</td>\n",
       "      <td>'Thanks  big  fan here'</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1540621789332257_1540637829330653</td>\n",
       "      <td>'Reminded of trika butterfly'</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1540621789332257_1540640095997093</td>\n",
       "      <td>'BEST WISHES FOR CELEBRATING... 34 YEARS..OF T...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1540621789332257_1540672129327223</td>\n",
       "      <td>'Congrats'</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1540621789332257_1540753779319058</td>\n",
       "      <td>'Congrats'</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1540621789332257_1540781092649660</td>\n",
       "      <td>'Congratulations'</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1540621789332257_1541729175888185</td>\n",
       "      <td>'Congratulations Apollo hospital...'</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1540621789332257_1541754942552275</td>\n",
       "      <td>'I will never forget the first class treatment...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1540621789332257_1542346075826495</td>\n",
       "      <td>\"Best wishes..and I'm so happy that I was a pa...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.998047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1538180652909704_1539762569418179</td>\n",
       "      <td>'Good Information which will help in curing pr...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.880859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          comment_id  \\\n",
       "0  1538183672909402_1541895645871538   \n",
       "1  1540621789332257_1540637829330653   \n",
       "2  1540621789332257_1540640095997093   \n",
       "3  1540621789332257_1540672129327223   \n",
       "4  1540621789332257_1540753779319058   \n",
       "5  1540621789332257_1540781092649660   \n",
       "6  1540621789332257_1541729175888185   \n",
       "7  1540621789332257_1541754942552275   \n",
       "8  1540621789332257_1542346075826495   \n",
       "9  1538180652909704_1539762569418179   \n",
       "\n",
       "                                     comment_message     label  certainty  \n",
       "0                            'Thanks  big  fan here'  Positive   0.880859  \n",
       "1                      'Reminded of trika butterfly'  Positive   0.880859  \n",
       "2  'BEST WISHES FOR CELEBRATING... 34 YEARS..OF T...  Positive   0.880859  \n",
       "3                                         'Congrats'  Positive   0.880859  \n",
       "4                                         'Congrats'  Positive   0.880859  \n",
       "5                                  'Congratulations'  Positive   0.880859  \n",
       "6               'Congratulations Apollo hospital...'  Positive   0.880859  \n",
       "7  'I will never forget the first class treatment...  Positive   0.880859  \n",
       "8  \"Best wishes..and I'm so happy that I was a pa...  Negative   0.998047  \n",
       "9  'Good Information which will help in curing pr...  Positive   0.880859  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writing output files to disk\n",
    "validattion_dataset_output_file = data_path + 'sentences_result.csv'\n",
    "validation_dataset.to_csv(validattion_dataset_output_file, header = None, index = False, columns = ['comment_id', 'comment_message','label','certainity'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
